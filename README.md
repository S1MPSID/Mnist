MNIST Digit Classification using ANN and CNN
ğŸ“Œ Project Overview

This project implements and compares different deep learning models for handwritten digit classification using the MNIST dataset. The work progresses from a simple Artificial Neural Network (ANN) baseline to a more advanced Convolutional Neural Network (CNN), and finally to a CNN with Dropout to reduce overfitting and improve generalization.

The models are developed and evaluated using TensorFlow and Keras in Google Colab.

ğŸ¯ Objectives

To understand and implement ANN and CNN architectures for image classification

To compare model performance on the MNIST dataset

To analyze overfitting and apply dropout regularization

To visualize and interpret training and validation performance

ğŸ“‚ Project Structure
â”œâ”€â”€ ann+cnn.py           # ANN and CNN baseline implementation
â”œâ”€â”€ cnn_dropout.py       # CNN with Dropout and performance analysis
â””â”€â”€ README.md            # Project documentation

ğŸ—‚ Dataset

Dataset: MNIST Handwritten Digits

Image size: 28 Ã— 28 (grayscale)

Classes: Digits 0â€“9

Training samples: 60,000

Test samples: 10,000

The dataset is loaded directly using tensorflow.keras.datasets.mnist.

ğŸ§  Models Implemented
1ï¸âƒ£ Artificial Neural Network (ANN)

Input images are flattened into a 1D vector

Fully connected dense layers with ReLU activation

Softmax output layer for multi-class classification

Purpose:
Serves as a baseline model for comparison.

2ï¸âƒ£ Convolutional Neural Network (CNN)

Convolution layers for feature extraction

Max pooling layers for dimensionality reduction

Dense layers for classification

Purpose:
Preserves spatial features in images and improves accuracy compared to ANN.

3ï¸âƒ£ CNN with Dropout

Dropout layers added after convolution and dense layers

Helps reduce overfitting by randomly deactivating neurons during training

Purpose:
Improves model generalization and stabilizes validation performance.

âš™ï¸ Implementation Details

Framework: TensorFlow (Keras API)

Optimizer: Adam

Loss Function: Sparse Categorical Crossentropy

Epochs: 5

Validation Split: 10%

Models are trained and evaluated on unseen test data to measure performance.

ğŸ“Š Results Summary
Model	Test Accuracy
ANN	~95â€“97%
CNN	~98â€“99%
CNN + Dropout	~97â€“98%

Training vs validation accuracy plots are generated to analyze overfitting behavior in the dropout model.

ğŸ” What the Code Does

Loads and preprocesses MNIST images

Trains ANN and CNN models to learn digit patterns

Evaluates model performance on test data

Visualizes predictions for selected test images

Saves trained CNN models for reuse

Analyzes generalization using dropout and accuracy curves

The models recognize handwritten digits from the MNIST dataset, not real-time user input.

ğŸ“ˆ Visualizations

Sample MNIST images

Model architecture summaries

Training and validation accuracy graphs

Predicted vs true label comparison for test samples

ğŸš€ Future Scope

Deployment of the trained CNN model in a web application

Extension to real-world handwritten digit inputs

Experimentation with deeper architectures and hyperparameter tuning

ğŸ Conclusion

This project demonstrates the effectiveness of CNNs over traditional ANN models for image classification tasks. It also highlights the importance of regularization techniques such as dropout to control overfitting and improve model robustness.
